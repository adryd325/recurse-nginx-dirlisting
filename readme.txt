scripts to recusively download the entire contents of a site using nginx directory listings
created for a quick thing but i figure others could possibly find it useful

start with `bash createtree.sh $URL`, then `node genurllist.js $PATH_TO_DOWNLOAD $BASE_URL` then `bash aria2.sh`

URL is url of the root of the directory listing eg. "https://example.com/directory_listing"
PATH_TO_DOWNLOAD is the folder generated by wget, typically the domain of the site eg. "./example.com"
BASE_URL is the root of the website eg. "https://example.com"
